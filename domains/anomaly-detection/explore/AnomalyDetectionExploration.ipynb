{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f0eabc4",
   "metadata": {},
   "source": [
    "# Anomaly Detection - Manual Exploration\n",
    "\n",
    "This notebook demonstrates different methods for anomaly detection for static code analysis data using jQAssistant and Neo4j. It plots results of different approaches from plain queries to statistical methods. The focus is on detecting anomalies in the data, which can be useful for identifying potential issues or areas for improvement in the codebase.\n",
    "\n",
    "<br>  \n",
    "\n",
    "### References\n",
    "- [jqassistant](https://jqassistant.org)\n",
    "- [Neo4j Python Driver](https://neo4j.com/docs/api/python-driver/current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0676813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following cell uses the build-in %html \"magic\" to override the CSS style for tables to a much smaller size.\n",
    "#This is especially needed for PDF export of tables with multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "/* CSS style for smaller dataframe tables. */\n",
    ".dataframe th {\n",
    "    font-size: 8px;\n",
    "}\n",
    ".dataframe td {\n",
    "    font-size: 8px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07319282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Colormap\n",
    "# main_color_map = 'nipy_spectral'\n",
    "main_color_map = 'viridis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import version as python_version\n",
    "print('Python version: {}'.format(python_version))\n",
    "\n",
    "from numpy import __version__ as numpy_version\n",
    "print('numpy version: {}'.format(numpy_version))\n",
    "\n",
    "from pandas import __version__ as pandas_version\n",
    "print('pandas version: {}'.format(pandas_version))\n",
    "\n",
    "from matplotlib import __version__ as matplotlib_version\n",
    "print('matplotlib version: {}'.format(matplotlib_version))\n",
    "\n",
    "from seaborn import __version__ as seaborn_version  # type: ignore\n",
    "print('seaborn version: {}'.format(seaborn_version))\n",
    "\n",
    "from neo4j import __version__ as neo4j_version\n",
    "print('neo4j version: {}'.format(neo4j_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please set the environment variable \"NEO4J_INITIAL_PASSWORD\" in your shell \n",
    "# before starting jupyter notebook to provide the password for the user \"neo4j\". \n",
    "# It is not recommended to hardcode the password into jupyter notebook for security reasons.\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    uri=\"bolt://localhost:7687\", \n",
    "    auth=(\"neo4j\", os.environ.get(\"NEO4J_INITIAL_PASSWORD\"))\n",
    ")\n",
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_cypher_to_data_frame(query: typing.LiteralString, parameters: typing.Optional[typing.Dict[str, typing.Any]] = None):\n",
    "    records, summary, keys = driver.execute_query(query, parameters_=parameters)\n",
    "    return pd.DataFrame([record.values() for record in records], columns=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7656bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_annotation_style: dict = {\n",
    "    'textcoords': 'offset points',\n",
    "    'arrowprops': dict(arrowstyle='->', color='black', alpha=0.3),\n",
    "    'fontsize': 6,\n",
    "    'backgroundcolor': 'white',\n",
    "    'bbox': dict(boxstyle='round,pad=0.4',\n",
    "                    edgecolor='silver',\n",
    "                    facecolor='whitesmoke',\n",
    "                    alpha=1\n",
    "                )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c68aa20",
   "metadata": {},
   "source": [
    "## 1. Java Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c927388f",
   "metadata": {},
   "source": [
    "### 1.1 Differences between Page Rank and Article Rank\n",
    "\n",
    "A high difference between Page Rank and Article Rank can reveal nodes with imbalanced roles â€” e.g. utility code that is highly depended on but does not depend on much else.\n",
    "\n",
    "PageRank measures how important a node is by who depends on it (high in-degree weight) while ArticleRank measures how important a node is based on how many other nodes it links to (outgoing edges matter more).\n",
    "\n",
    "Nodes with low PageRank but high ArticleRank may be coordination-heavy, which could signal:\n",
    "- Unusual architecture\n",
    "- Utility overuse\n",
    "- Monolithic patterns\n",
    "\n",
    "These are often design smells or potential anomalies in large-scale codebases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_package_centrality_features_query = \"\"\"\n",
    "    MATCH (artifact:Java:Artifact)-[:CONTAINS]->(codeUnit:Java:Package)\n",
    "    WHERE codeUnit.incomingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.outgoingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.centralityArticleRank                       IS NOT NULL\n",
    "      AND codeUnit.centralityPageRank                          IS NOT NULL\n",
    "      AND codeUnit.centralityBetweenness                       IS NOT NULL\n",
    "   RETURN DISTINCT \n",
    "         codeUnit.fqn                                         AS codeUnitName\n",
    "        ,codeUnit.name                                        AS shortCodeUnitName\n",
    "        ,artifact.name                                        AS projectName\n",
    "        ,codeUnit.incomingDependencies                        AS incomingDependencies\n",
    "        ,codeUnit.outgoingDependencies                        AS outgoingDependencies\n",
    "        ,codeUnit.centralityArticleRank                       AS articleRank\n",
    "        ,codeUnit.centralityPageRank                          AS pageRank\n",
    "        ,codeUnit.centralityBetweenness                       AS betweenness\n",
    "\"\"\"\n",
    "\n",
    "java_package_centrality_features = query_cypher_to_data_frame(java_package_centrality_features_query)\n",
    "display(java_package_centrality_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb417d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_standard_deviation_lines(color: typing.LiteralString, mean: float, standard_deviation: float, standard_deviation_factor: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Plots vertical lines for the mean + factor times standard deviation (z-score references).\n",
    "    \"\"\"\n",
    "    # Vertical line for the standard deviation\n",
    "    positive_standard_deviation = mean + (standard_deviation_factor * standard_deviation)\n",
    "    horizontal_line_label = f'Mean + {standard_deviation_factor} x Standard Deviation: {positive_standard_deviation:.2f}' if standard_deviation_factor != 0 else f'Mean: {mean:.2f}'\n",
    "    \n",
    "    plot.axvline(positive_standard_deviation, color=color, linestyle='dashed', linewidth=1, label=horizontal_line_label)\n",
    "    \n",
    "    if standard_deviation_factor != 0:\n",
    "        negative_standard_deviation = mean - (standard_deviation_factor * standard_deviation)\n",
    "        plot.axvline(negative_standard_deviation, color=color, linestyle='dashed', linewidth=1)\n",
    "        \n",
    "    plot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference_between_article_and_page_rank(\n",
    "    page_ranks: pd.Series, \n",
    "    article_ranks: pd.Series,\n",
    "    short_names: pd.Series,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots the difference between Article Rank and Page Rank for Java packages.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    page_ranks : pd.Series\n",
    "        DataFrame column containing Page Rank values.\n",
    "    article_ranks : pd.Series\n",
    "        DataFrame column containing Article Rank values.\n",
    "    short_names : pd.Series\n",
    "        DataFrame column containing short names of the code units.\n",
    "    \"\"\"\n",
    "    if page_ranks.empty or article_ranks.empty or short_names.empty:\n",
    "        print(\"No data available to plot.\")\n",
    "        return\n",
    "\n",
    "    # Calculate the difference between Article Rank and Page Rank\n",
    "    page_to_article_rank_difference = page_ranks - article_ranks\n",
    "\n",
    "    plot.figure(figsize=(10, 6))\n",
    "    plot.hist(page_to_article_rank_difference, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "    plot.title('Distribution of Page Rank - Article Rank Difference')\n",
    "    plot.xlabel('Absolute difference between Page Rank and Article Rank')\n",
    "    plot.ylabel('Frequency')\n",
    "    plot.xlim(left=page_to_article_rank_difference.min(), right=page_to_article_rank_difference.max())\n",
    "    plot.yscale('log')  # Use logarithmic scale for better visibility of differences\n",
    "    plot.grid(True)\n",
    "    plot.tight_layout()\n",
    "\n",
    "    mean_difference = page_to_article_rank_difference.mean()\n",
    "    standard_deviation = page_to_article_rank_difference.std()\n",
    "    \n",
    "    # Vertical line for the mean\n",
    "    plot_standard_deviation_lines('red', mean_difference, standard_deviation, standard_deviation_factor=0)\n",
    "    # Vertical line for the standard deviation + mean (=z-score of 1)\n",
    "    plot_standard_deviation_lines('orange', mean_difference, standard_deviation, standard_deviation_factor=1)\n",
    "    # Vertical line for 2 x standard deviations + mean (=z-score of 2)\n",
    "    plot_standard_deviation_lines('green', mean_difference, standard_deviation, standard_deviation_factor=2)\n",
    "\n",
    "    def annotate_outliers(outliers: pd.DataFrame) -> None:\n",
    "        if outliers.empty:\n",
    "            return\n",
    "        for dataframe_index, row in outliers.iterrows():\n",
    "            index = typing.cast(int, dataframe_index)\n",
    "            value = row['pageToArticleRankDifference']\n",
    "            x_index_offset = - index * 10 if value > 0 else + index * 10\n",
    "            plot.annotate(\n",
    "                text=f'{row['shortName']} (rank #{row['page_rank_ranking']}, #{row['article_rank_ranking']})',\n",
    "                xy=(value, 1),\n",
    "                xytext=(value + x_index_offset, 60),\n",
    "                rotation=90,\n",
    "                **plot_annotation_style,\n",
    "            )\n",
    "\n",
    "    # Merge all series into a single DataFrame for easier handling\n",
    "    page_to_article_rank_dataframe = pd.DataFrame({\n",
    "        'shortName': short_names,\n",
    "        'pageRank': page_ranks,\n",
    "        'articleRank': article_ranks,\n",
    "        'pageToArticleRankDifference': page_to_article_rank_difference,\n",
    "        'page_rank_ranking': page_ranks.rank().astype(int),\n",
    "        'article_rank_ranking': article_ranks.rank().astype(int)\n",
    "    }, index=page_ranks.index)\n",
    "\n",
    "    # Annotate values above z-score of 2 with their names\n",
    "    positive_z_score_2 = mean_difference + 2 * standard_deviation\n",
    "    positive_outliers = page_to_article_rank_dataframe[page_to_article_rank_difference > positive_z_score_2].sort_values(by='pageToArticleRankDifference', ascending=False).reset_index().head(5)\n",
    "    annotate_outliers(positive_outliers)\n",
    "\n",
    "    # Annotate values below z-score of -2 with their names\n",
    "    negative_z_score_2 = mean_difference - 2 * standard_deviation\n",
    "    negative_outliers = page_to_article_rank_dataframe[page_to_article_rank_difference < negative_z_score_2].sort_values(by='pageToArticleRankDifference', ascending=True).reset_index().head(5)\n",
    "    annotate_outliers(negative_outliers)\n",
    "\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_difference_between_article_and_page_rank(\n",
    "    java_package_centrality_features['pageRank'],\n",
    "    java_package_centrality_features['articleRank'],\n",
    "    java_package_centrality_features['shortCodeUnitName']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec26a8",
   "metadata": {},
   "source": [
    "### 1.2 Local Clustering Coefficient\n",
    "\n",
    "The local clustering coefficient is a measure of how connected a node's neighbors are to each other.\n",
    "A high local clustering coefficient indicates that a node's neighbors are well-connected, which can suggest a tightly-knit group of related components or classes.\n",
    "A low local clustering coefficient may indicate that a node's neighbors are not well-connected, which can suggest a more loosely-coupled architecture or potential design smells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740699a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_package_clustering_coefficient_query = \"\"\"\n",
    "    MATCH (artifact:Java:Artifact)-[:CONTAINS]->(codeUnit:Java:Package)\n",
    "    WHERE codeUnit.incomingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.outgoingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.centralityPageRank                          IS NOT NULL\n",
    "      AND codeUnit.communityLocalClusteringCoefficient         IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANNoise                      IS NOT NULL\n",
    "   RETURN DISTINCT \n",
    "         codeUnit.fqn                                         AS codeUnitName\n",
    "        ,codeUnit.name                                        AS shortCodeUnitName\n",
    "        ,artifact.name                                        AS projectName\n",
    "        ,codeUnit.incomingDependencies                        AS incomingDependencies\n",
    "        ,codeUnit.outgoingDependencies                        AS outgoingDependencies\n",
    "        ,codeUnit.centralityPageRank                          AS pageRank\n",
    "        ,codeUnit.communityLocalClusteringCoefficient         AS clusteringCoefficient\n",
    "        ,codeUnit.clusteringHDBSCANNoise                      AS clusterNoise\n",
    "\"\"\"\n",
    "\n",
    "java_package_clustering_coefficient_features = query_cypher_to_data_frame(java_package_clustering_coefficient_query)\n",
    "display(java_package_clustering_coefficient_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed900c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_coefficient_distribution(clustering_coefficients: pd.Series) -> None:\n",
    "    \"\"\"\n",
    "    Plots the distribution of clustering coefficients.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clustering_coefficients : pd.Series\n",
    "        Series containing clustering coefficient values.\n",
    "    \"\"\"\n",
    "    if clustering_coefficients.empty:\n",
    "        print(\"No data available to plot.\")\n",
    "        return\n",
    "\n",
    "    plot.figure(figsize=(10, 6))\n",
    "    plot.figure(figsize=(10, 6))\n",
    "    plot.hist(clustering_coefficients, bins=40, color='blue', alpha=0.7, edgecolor='black')\n",
    "    plot.title('Distribution of Clustering Coefficients')\n",
    "    plot.xlabel('Clustering Coefficient')\n",
    "    plot.ylabel('Frequency')\n",
    "    plot.xlim(left=clustering_coefficients.min(), right=clustering_coefficients.max())\n",
    "    # plot.yscale('log')  # Use logarithmic scale for better visibility of differences\n",
    "    plot.grid(True)\n",
    "    plot.tight_layout()\n",
    "\n",
    "    mean = clustering_coefficients.mean()\n",
    "    standard_deviation = clustering_coefficients.std()\n",
    "\n",
    "    # Vertical line for the mean\n",
    "    plot_standard_deviation_lines('red', mean, standard_deviation, standard_deviation_factor=0)\n",
    "    # Vertical line for 1 x standard deviations + mean (=z-score of 1)\n",
    "    plot_standard_deviation_lines('green', mean, standard_deviation, standard_deviation_factor=1)\n",
    "\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05994e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering_coefficient_distribution(java_package_clustering_coefficient_features['clusteringCoefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f46116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_coefficient_vs_page_rank(\n",
    "    clustering_coefficients: pd.Series, \n",
    "    page_ranks: pd.Series,\n",
    "    short_names: pd.Series,\n",
    "    clustering_noise: pd.Series,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots the relationship between clustering coefficients and Page Rank values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clustering_coefficients : pd.Series\n",
    "        Series containing clustering coefficient values.\n",
    "    page_ranks : pd.Series\n",
    "        Series containing Page Rank values.\n",
    "    short_names : pd.Series\n",
    "        Series containing short names of the code units.\n",
    "    clustering_noise : pd.Series\n",
    "        Series indicating whether the code unit is noise (value = 1) nor not (value = 0) from the clustering algorithm.\n",
    "    \"\"\"\n",
    "    if clustering_coefficients.empty or page_ranks.empty or short_names.empty:\n",
    "        print(\"No data available to plot.\")\n",
    "        return\n",
    "\n",
    "    color = clustering_noise.map({0: 'blue', 1: 'gray'})\n",
    "\n",
    "    plot.figure(figsize=(10, 6))\n",
    "    plot.scatter(x=clustering_coefficients, y=page_ranks, alpha=0.7, color=color)\n",
    "    plot.title('Clustering Coefficient vs Page Rank')\n",
    "    plot.xlabel('Clustering Coefficient')\n",
    "    plot.ylabel('Page Rank')\n",
    "\n",
    "    # Add color bar: grey = noise, blue = non-noise\n",
    "    scatter = plot.scatter([], [], color='blue', label='Non-Noise', alpha=0.7)\n",
    "    scatter_noise = plot.scatter([], [], color='gray', label='Noise', alpha=0.7)\n",
    "    plot.legend(handles=[scatter, scatter_noise], loc='upper right', title='Clustering Noise')\n",
    "    \n",
    "    # Merge all series into a single DataFrame for easier handling\n",
    "    combined_data = pd.DataFrame({\n",
    "        'shortName': short_names,\n",
    "        'clusteringCoefficient': clustering_coefficients,\n",
    "        'pageRank': page_ranks,\n",
    "        'clusterNoise': clustering_noise,\n",
    "    }, index=clustering_coefficients.index)\n",
    "\n",
    "    # Annotate points with their names. Filter out values with a page rank smaller than 1.5 standard deviations\n",
    "    mean_page_rank = page_ranks.mean()\n",
    "    standard_deviation_page_rank = page_ranks.std()\n",
    "    threshold_page_rank = mean_page_rank + 1.5 * standard_deviation_page_rank\n",
    "    significant_points = combined_data[combined_data['pageRank'] > threshold_page_rank].reset_index(drop=True).head(10)\n",
    "    for dataframe_index, row in significant_points.iterrows():\n",
    "        index = typing.cast(int, dataframe_index)\n",
    "        plot.annotate(\n",
    "            text=row['shortName'],\n",
    "            xy=(row['clusteringCoefficient'], row['pageRank']),\n",
    "            xytext=(5, 5 + index * 10),  # Offset y position for better visibility\n",
    "            **plot_annotation_style\n",
    "        )\n",
    "\n",
    "    # Annotate points with the highest clustering coefficients (top 20) and only show the lowest 5 page ranks\n",
    "    combined_data['page_rank_ranking'] = combined_data['pageRank'].rank(ascending=False).astype(int)\n",
    "    combined_data['clustering_coefficient_ranking'] = combined_data['clusteringCoefficient'].rank(ascending=False).astype(int)\n",
    "    top_clustering_coefficients = combined_data.sort_values(by='clusteringCoefficient', ascending=False).reset_index(drop=True).head(20)\n",
    "    top_clustering_coefficients = top_clustering_coefficients.sort_values(by='pageRank', ascending=True).reset_index(drop=True).head(5)\n",
    "    for dataframe_index, row in top_clustering_coefficients.iterrows():\n",
    "        index = typing.cast(int, dataframe_index)\n",
    "        plot.annotate(\n",
    "            text=f\"{row['shortName']} (score {row['pageRank']:.4f})\",\n",
    "            xy=(row['clusteringCoefficient'], row['pageRank']),\n",
    "            xytext=(5, 5 + index * 10),  # Offset y position for better visibility\n",
    "            **plot_annotation_style\n",
    "        )\n",
    "\n",
    "    #plot.yscale('log')  # Use logarithmic scale for better visibility of differences\n",
    "    plot.grid(True)\n",
    "    plot.tight_layout()\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering_coefficient_vs_page_rank(\n",
    "    java_package_clustering_coefficient_features['clusteringCoefficient'],\n",
    "    java_package_centrality_features['pageRank'],\n",
    "    java_package_clustering_coefficient_features['shortCodeUnitName'],\n",
    "    java_package_clustering_coefficient_features['clusterNoise']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f5e4b",
   "metadata": {},
   "source": [
    "### 1.3 HDBSCAN Clusters\n",
    "\n",
    "HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) is a clustering algorithm that can identify clusters of varying densities and shapes. It is particularly useful for detecting anomalies in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb4eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_package_clustering_query = \"\"\"\n",
    "    MATCH (artifact:Java:Artifact)-[:CONTAINS]->(codeUnit:Java:Package)\n",
    "    WHERE codeUnit.incomingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.outgoingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.centralityPageRank                          IS NOT NULL\n",
    "      AND codeUnit.centralityArticleRank                       IS NOT NULL\n",
    "      AND codeUnit.communityLocalClusteringCoefficient         IS NOT NULL\n",
    "      AND codeUnit.centralityBetweenness                       IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANLabel                      IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANProbability                IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANNoise                      IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANMedoid                     IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANSize                       IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANRadiusMax                  IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANRadiusAverage              IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANNormalizedDistanceToMedoid IS NOT NULL\n",
    "      AND codeUnit.embeddingsFastRandomProjectionTunedForClusteringVisualizationX IS NOT NULL\n",
    "      AND codeUnit.embeddingsFastRandomProjectionTunedForClusteringVisualizationY IS NOT NULL\n",
    "   RETURN DISTINCT \n",
    "         codeUnit.fqn                                         AS codeUnitName\n",
    "        ,codeUnit.name                                        AS shortCodeUnitName\n",
    "        ,artifact.name                                        AS projectName\n",
    "        ,codeUnit.incomingDependencies                        AS incomingDependencies\n",
    "        ,codeUnit.outgoingDependencies                        AS outgoingDependencies\n",
    "        ,codeUnit.centralityPageRank                          AS pageRank\n",
    "        ,1.0 - codeUnit.communityLocalClusteringCoefficient   AS inverseClusteringCoefficient\n",
    "        ,codeUnit.centralityBetweenness                       AS betweenness\n",
    "        ,codeUnit.centralityPageRank - codeUnit.centralityArticleRank AS pageToArticleRankDifference\n",
    "        ,codeUnit.clusteringHDBSCANLabel                      AS clusterLabel\n",
    "        ,codeUnit.clusteringHDBSCANProbability                AS clusterProbability\n",
    "        ,codeUnit.clusteringHDBSCANNoise                      AS clusterNoise\n",
    "        ,codeUnit.clusteringHDBSCANMedoid                     AS clusterMedoid\n",
    "        ,codeUnit.clusteringHDBSCANSize                       AS clusterSize\n",
    "        ,codeUnit.clusteringHDBSCANRadiusMax                  AS clusterRadiusMax\n",
    "        ,codeUnit.clusteringHDBSCANRadiusAverage              AS clusterRadiusAverage\n",
    "        ,codeUnit.clusteringHDBSCANNormalizedDistanceToMedoid AS clusterNormalizedDistanceToMedoid\n",
    "        ,codeUnit.embeddingsFastRandomProjectionTunedForClusteringVisualizationX AS embeddingVisualizationX\n",
    "        ,codeUnit.embeddingsFastRandomProjectionTunedForClusteringVisualizationY AS embeddingVisualizationY\n",
    "    \"\"\"\n",
    "\n",
    "java_package_clustering_features = query_cypher_to_data_frame(java_package_clustering_query)\n",
    "java_package_clustering_features['degree'] = java_package_clustering_features['incomingDependencies'] + java_package_clustering_features['outgoingDependencies']\n",
    "display(java_package_clustering_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_visualization_cluster_diameter(\n",
    "    clustering_visualization_dataframe: pd.DataFrame,\n",
    "    result_diameter_column_name: str = 'clusterVisualizationDiameter',\n",
    "    cluster_label_column_name: str = \"clusterLabel\",\n",
    "    x_position_column: str = \"embeddingVisualizationX\",\n",
    "    y_position_column: str = \"embeddingVisualizationY\",\n",
    "):\n",
    "    \n",
    "    def max_pairwise_distance(points):\n",
    "        if len(points) < 2:\n",
    "            return 0.0\n",
    "        # Efficient vectorized pairwise distance computation\n",
    "        dists = np.sqrt(\n",
    "            np.sum((points[:, np.newaxis, :] - points[np.newaxis, :, :]) ** 2, axis=-1)\n",
    "        )\n",
    "        return np.max(dists)\n",
    "    \n",
    "    unique_cluster_labels = clustering_visualization_dataframe[cluster_label_column_name].unique()\n",
    "    \n",
    "    if len(unique_cluster_labels) == 0:\n",
    "        return \n",
    "\n",
    "    cluster_diameters = {}\n",
    "    for cluster_label in unique_cluster_labels:\n",
    "        if cluster_label == -1:\n",
    "            cluster_diameters[-1] = 0.0\n",
    "            continue\n",
    "        \n",
    "        cluster_nodes = clustering_visualization_dataframe[\n",
    "            clustering_visualization_dataframe[cluster_label_column_name] == cluster_label\n",
    "        ]\n",
    "        cluster_diameters[cluster_label] = max_pairwise_distance(cluster_nodes[[x_position_column, y_position_column]].to_numpy())\n",
    "\n",
    "    if cluster_diameters:\n",
    "        clustering_visualization_dataframe[result_diameter_column_name] = clustering_visualization_dataframe[cluster_label_column_name].map(cluster_diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_visualization_cluster_diameter(java_package_clustering_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18125c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters_by_criteria(\n",
    "        dataframe: pd.DataFrame, \n",
    "        by: str, \n",
    "        ascending: bool = True, \n",
    "        cluster_count: int = 10, \n",
    "        label_column_name: str = 'clusterLabel'\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Returns the rows for the \"cluster_count\" clusters with the largest (ascending=False) or smallest(ascending=True)\n",
    "    value in the column specified with \"by\". Noise (labeled with -1) remains unfiltered.\n",
    "    \"\"\"\n",
    "    if ascending:\n",
    "        threshold = dataframe.groupby(by=label_column_name)[by].min().nsmallest(cluster_count).iloc[-1]\n",
    "        #print(f\"Ascending threshold is {threshold} for {by}.\")\n",
    "        return dataframe[(dataframe[by] <= threshold) | (dataframe[label_column_name] == -1)]\n",
    "    \n",
    "    threshold = dataframe.groupby(by=label_column_name)[by].max().nlargest(cluster_count).iloc[-1]\n",
    "    #print(f\"Descending threshold is {threshold} for {by}.\")\n",
    "    return dataframe[(dataframe[by] >= threshold) | (dataframe[label_column_name] == -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(\n",
    "    clustering_visualization_dataframe: pd.DataFrame,\n",
    "    title: str,\n",
    "    main_color_map: str = \"tab20\",\n",
    "    code_unit_column_name: str = \"shortCodeUnitName\",\n",
    "    cluster_label_column_name: str = \"clusterLabel\",\n",
    "    cluster_medoid_column_name: str = \"clusterMedoid\",\n",
    "    centrality_column_name: str = \"pageRank\",\n",
    "    x_position_column: str = 'embeddingVisualizationX',\n",
    "    y_position_column: str = 'embeddingVisualizationY',\n",
    "    cluster_visualization_diameter_column = 'clusterVisualizationDiameter'\n",
    ") -> None:\n",
    "    \n",
    "    if clustering_visualization_dataframe.empty:\n",
    "        print(\"No projected data to plot available\")\n",
    "        return\n",
    "    \n",
    "    def truncate(text: str, max_length: int):\n",
    "        if len(text) <= max_length:\n",
    "            return text\n",
    "        return text[:max_length - 3] + \"...\"\n",
    "    \n",
    "    # Create figure and subplots\n",
    "    plot.figure(figsize=(10, 10))\n",
    "\n",
    "    # Setup columns\n",
    "    node_size_column = centrality_column_name\n",
    "\n",
    "    # Separate HDBSCAN non-noise and noise nodes\n",
    "    node_embeddings_without_noise = clustering_visualization_dataframe[clustering_visualization_dataframe[cluster_label_column_name] != -1]\n",
    "    node_embeddings_noise_only = clustering_visualization_dataframe[clustering_visualization_dataframe[cluster_label_column_name] == -1]\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Subplot: HDBSCAN Clustering with KDE\n",
    "    # ------------------------------------------\n",
    "    plot.title(title)\n",
    "\n",
    "    unique_cluster_labels = node_embeddings_without_noise[cluster_label_column_name].unique()\n",
    "    hdbscan_color_palette = seaborn.color_palette(main_color_map, len(unique_cluster_labels))\n",
    "    hdbscan_cluster_to_color = dict(zip(unique_cluster_labels, hdbscan_color_palette))\n",
    "\n",
    "    max_visualization_diameter = node_embeddings_without_noise[cluster_visualization_diameter_column].max()\n",
    "    visualization_diameter_normalization_factor = max_visualization_diameter * 2\n",
    "\n",
    "    for cluster_label in unique_cluster_labels:\n",
    "        cluster_nodes = node_embeddings_without_noise[\n",
    "            node_embeddings_without_noise[cluster_label_column_name] == cluster_label\n",
    "        ]\n",
    "        # By comparing the cluster diameter to the max diameter of all clusters in the quartile,\n",
    "        # we can adjust the alpha value for the KDE plot to visualize smaller clusters more clearly.\n",
    "        # This way, larger clusters will have a lower alpha value, making them less prominent and less prone to overshadow smaller clusters.\n",
    "        cluster_diameter = cluster_nodes.iloc[0][cluster_visualization_diameter_column]\n",
    "        alpha = max((1.0 - (cluster_diameter / (visualization_diameter_normalization_factor))) * 0.45 - 0.25, 0.02)\n",
    "\n",
    "        # KDE cloud shape\n",
    "        if len(cluster_nodes) > 1 and (\n",
    "            cluster_nodes[x_position_column].std() > 0 or cluster_nodes[y_position_column].std() > 0\n",
    "        ):\n",
    "            seaborn.kdeplot(\n",
    "                x=cluster_nodes[x_position_column],\n",
    "                y=cluster_nodes[y_position_column],\n",
    "                fill=True,\n",
    "                alpha=alpha,\n",
    "                levels=2,\n",
    "                color=hdbscan_cluster_to_color[cluster_label],\n",
    "                ax=plot.gca(),  # Use current axes\n",
    "                warn_singular=False,\n",
    "            )\n",
    "\n",
    "        # Node scatter points\n",
    "        plot.scatter(\n",
    "            x=cluster_nodes[x_position_column],\n",
    "            y=cluster_nodes[y_position_column],\n",
    "            s=cluster_nodes[node_size_column] * 200 + 2,\n",
    "            color=hdbscan_cluster_to_color[cluster_label],\n",
    "            alpha=0.9,\n",
    "            label=f\"Cluster {cluster_label}\"\n",
    "        )\n",
    "\n",
    "        # Annotate medoids of the cluster\n",
    "        medoids = cluster_nodes[cluster_nodes[cluster_medoid_column_name] == 1]\n",
    "        for index, row in medoids.iterrows():\n",
    "            plot.annotate(\n",
    "                text=f\"{truncate(row[code_unit_column_name], 30)} ({row[cluster_label_column_name]})\",\n",
    "                xy=(row[x_position_column], row[y_position_column]),\n",
    "                xytext=(5, 5),  # Offset for better visibility\n",
    "                **plot_annotation_style\n",
    "            )\n",
    "\n",
    "    # Plot noise points in gray\n",
    "    plot.scatter(\n",
    "        x=node_embeddings_noise_only[x_position_column],\n",
    "        y=node_embeddings_noise_only[y_position_column],\n",
    "        s=node_embeddings_noise_only[node_size_column] * 200 + 2,\n",
    "        color='lightgrey',\n",
    "        alpha=0.4,\n",
    "        label=\"Noise\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_package_clustering_features_filtered=get_clusters_by_criteria(\n",
    "    java_package_clustering_features, by='clusterSize', ascending=False, cluster_count=20\n",
    ")\n",
    "plot_clusters(\n",
    "    clustering_visualization_dataframe=java_package_clustering_features_filtered,\n",
    "    title=\"Java Package Clusters with the largest size\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_package_clustering_features_filtered=get_clusters_by_criteria(\n",
    "    java_package_clustering_features, by='clusterRadiusMax', ascending=False, cluster_count=20\n",
    ")\n",
    "plot_clusters(\n",
    "    clustering_visualization_dataframe=java_package_clustering_features_filtered,\n",
    "    title=\"Java Package Clusters with the biggest max radius\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec816783",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_package_clustering_features_filtered=get_clusters_by_criteria(\n",
    "    java_package_clustering_features, by='clusterRadiusAverage', ascending=False, cluster_count=20\n",
    ")\n",
    "plot_clusters(\n",
    "    clustering_visualization_dataframe=java_package_clustering_features_filtered,\n",
    "    title=\"Java Package Clusters with the biggest average radius\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters_probabilities(\n",
    "    clustering_visualization_dataframe: pd.DataFrame,\n",
    "    title: str,\n",
    "    code_unit_column: str = \"shortCodeUnitName\",\n",
    "    cluster_label_column: str = \"clusterLabel\",\n",
    "    cluster_medoid_column: str = \"clusterMedoid\",\n",
    "    cluster_size_column: str = \"clusterSize\",\n",
    "    cluster_probability_column: str = \"clusterProbability\",\n",
    "    size_column: str = \"pageRank\",\n",
    "    x_position_column: str = 'embeddingVisualizationX',\n",
    "    y_position_column: str = 'embeddingVisualizationY',\n",
    ") -> None:\n",
    "    \n",
    "    if clustering_visualization_dataframe.empty:\n",
    "        print(\"No projected data to plot available\")\n",
    "        return\n",
    "    \n",
    "    def truncate(text: str, max_length: int):\n",
    "        if len(text) <= max_length:\n",
    "            return text\n",
    "        return text[:max_length - 3] + \"...\"\n",
    "    \n",
    "    cluster_noise = clustering_visualization_dataframe[clustering_visualization_dataframe[cluster_label_column] == -1]\n",
    "    cluster_non_noise = clustering_visualization_dataframe[clustering_visualization_dataframe[cluster_label_column] != -1]\n",
    "    cluster_even_labels = clustering_visualization_dataframe[clustering_visualization_dataframe[cluster_label_column] % 2 == 0]\n",
    "    cluster_odd_labels = clustering_visualization_dataframe[clustering_visualization_dataframe[cluster_label_column] % 2 == 1]\n",
    "\n",
    "    plot.figure(figsize=(10, 10))\n",
    "    plot.title(title)\n",
    "\n",
    "    # Plot noise\n",
    "    plot.scatter(\n",
    "        x=cluster_noise[x_position_column],\n",
    "        y=cluster_noise[y_position_column],\n",
    "        s=cluster_noise[size_column] * 200 + 3,\n",
    "        color='lightgrey',\n",
    "        alpha=0.5,\n",
    "        label='Noise'\n",
    "    )\n",
    "\n",
    "    # Plot even labels\n",
    "    plot.scatter(\n",
    "        x=cluster_even_labels[x_position_column],\n",
    "        y=cluster_even_labels[y_position_column],\n",
    "        s=cluster_even_labels[size_column] * 200 + 3,\n",
    "        c=cluster_even_labels[cluster_probability_column],\n",
    "        vmin=0.6,\n",
    "        vmax=1.0,\n",
    "        cmap='Greens',\n",
    "        alpha=0.8,\n",
    "        label='Even Label'\n",
    "    )\n",
    "\n",
    "    # Plot odd labels\n",
    "    plot.scatter(\n",
    "        x=cluster_odd_labels[x_position_column],\n",
    "        y=cluster_odd_labels[y_position_column],\n",
    "        s=cluster_odd_labels[size_column] * 200 + 3,\n",
    "        c=cluster_odd_labels[cluster_probability_column],\n",
    "        vmin=0.6,\n",
    "        vmax=1.0,\n",
    "        cmap='Blues',\n",
    "        alpha=0.8,\n",
    "        label='Odd Label'\n",
    "    )\n",
    "\n",
    "    # Annotate medoids of the cluster\n",
    "    cluster_medoids = cluster_non_noise[cluster_non_noise[cluster_medoid_column] == 1].sort_values(by=cluster_size_column, ascending=False).head(20)\n",
    "    for index, row in cluster_medoids.iterrows():\n",
    "        mean_cluster_probability = cluster_non_noise[cluster_non_noise[cluster_label_column] == row[cluster_label_column]][cluster_probability_column].mean()\n",
    "        plot.annotate(\n",
    "            text=f\"{row[cluster_label_column]}:{truncate(row[code_unit_column], 20)} ({mean_cluster_probability:.4f})\",\n",
    "            xy=(row[x_position_column], row[y_position_column]),\n",
    "            xytext=(5, 5),\n",
    "            alpha=0.5,\n",
    "            **plot_annotation_style\n",
    "        )\n",
    "\n",
    "    lowest_probabilities = cluster_non_noise.sort_values(by=cluster_probability_column, ascending=True).reset_index().head(10)\n",
    "    for dataframe_index, row in lowest_probabilities.iterrows():\n",
    "        index = typing.cast(int, dataframe_index)\n",
    "        plot.annotate(\n",
    "            text=f\"!{row[cluster_label_column]}:{truncate(row[code_unit_column], 20)} ({row[cluster_probability_column]:.4f})\",\n",
    "            xy=(row[x_position_column], row[y_position_column]),\n",
    "            xytext=(5, 5 + index * 10),\n",
    "            color='red',\n",
    "            **plot_annotation_style\n",
    "        )\n",
    "\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters_probabilities(java_package_clustering_features, \"Java Package Clustering Probabilities (red=high uncertainty)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9580ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_noise(\n",
    "    clustering_visualization_dataframe: pd.DataFrame,\n",
    "    title: str,\n",
    "    code_unit_column_name: str = \"shortCodeUnitName\",\n",
    "    cluster_label_column_name: str = \"clusterLabel\",\n",
    "    size_column_name: str = \"degree\",\n",
    "    color_column_name: str = \"pageRank\",\n",
    "    x_position_column = 'embeddingVisualizationX',\n",
    "    y_position_column = 'embeddingVisualizationY'\n",
    ") -> None:\n",
    "    if clustering_visualization_dataframe.empty:\n",
    "        print(\"No projected data to plot available\")\n",
    "        return\n",
    "\n",
    "    # Filter only noise points\n",
    "    noise_points = clustering_visualization_dataframe[clustering_visualization_dataframe[cluster_label_column_name] == -1]\n",
    "    noise_points = noise_points.sort_values(by=size_column_name, ascending=False).reset_index(drop=True)\n",
    "\n",
    "    if noise_points.empty:\n",
    "        print(\"No noise points to plot.\")\n",
    "        return\n",
    "\n",
    "    plot.figure(figsize=(10, 10))\n",
    "    plot.title(title)\n",
    "\n",
    "    # Determine the color threshold for noise points\n",
    "    color_10th_highest_value = noise_points[color_column_name].nlargest(10).iloc[-1]  # Get the 10th largest value\n",
    "    color_90_quantile = noise_points[color_column_name].quantile(0.90)\n",
    "    color_threshold = max(color_10th_highest_value, color_90_quantile)\n",
    "\n",
    "    # Color the color column values above the 90% quantile threshold red, the rest light grey \n",
    "    colors = noise_points[color_column_name].apply(\n",
    "        lambda x: \"red\" if x >= color_threshold else \"lightgrey\"\n",
    "    )\n",
    "    normalized_size = noise_points[size_column_name] / noise_points[size_column_name].max()\n",
    "\n",
    "    # Scatter plot for noise points\n",
    "    scatter = plot.scatter(\n",
    "        x=noise_points[x_position_column],\n",
    "        y=noise_points[y_position_column],\n",
    "        s=normalized_size.clip(lower=0.01) * 800 + 2,\n",
    "        c=colors,\n",
    "        alpha=0.6\n",
    "    )\n",
    "\n",
    "    # Annotate the largest 10 points and all colored ones with their names\n",
    "    for index, row in noise_points.iterrows():\n",
    "        index = typing.cast(int, index)\n",
    "        if colors[index] != 'red' and index >= 10:\n",
    "            continue\n",
    "        plot.annotate(\n",
    "            text=row[code_unit_column_name],\n",
    "            xy=(row[x_position_column], row[y_position_column]),\n",
    "            xytext=(5, 5 + (index % 2) * 20),  # Offset for better visibility\n",
    "            **plot_annotation_style\n",
    "        )\n",
    "\n",
    "    plot.xlabel(x_position_column)\n",
    "    plot.ylabel(y_position_column)\n",
    "    plot.tight_layout()\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_noise(\n",
    "    clustering_visualization_dataframe=java_package_clustering_features,\n",
    "    title=\"Java Package Clustering Noise points that are surprisingly central (color) or popular (size)\",\n",
    "    size_column_name='degree',\n",
    "    color_column_name='pageRank'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_noise(\n",
    "    clustering_visualization_dataframe=java_package_clustering_features,\n",
    "    title=\"Java Package Clustering Noise points that bridge flow (color) and are poorly integrated (size)\",\n",
    "    size_column_name='inverseClusteringCoefficient',\n",
    "    color_column_name='betweenness'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_noise(\n",
    "    clustering_visualization_dataframe=java_package_clustering_features,\n",
    "    title=\"Java Package Clustering Noise points with role inversion (size), possibly violating layering or dependency direction (color)\",\n",
    "    size_column_name='pageToArticleRankDifference',\n",
    "    color_column_name='betweenness'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682bb64",
   "metadata": {},
   "source": [
    "## 2. Java Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25370d7f",
   "metadata": {},
   "source": [
    "### 2.1 Differences between Page Rand and Article Rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_type_anomaly_detection_centrality_features_query = \"\"\"\n",
    "    MATCH (artifact:Java:Artifact)-[:CONTAINS]->(codeUnit:Java:Type)\n",
    "    WHERE codeUnit.incomingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.outgoingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.centralityArticleRank                       IS NOT NULL\n",
    "      AND codeUnit.centralityPageRank                          IS NOT NULL\n",
    "      AND codeUnit.centralityBetweenness                       IS NOT NULL\n",
    "   RETURN DISTINCT \n",
    "         codeUnit.fqn                                         AS codeUnitName\n",
    "        ,codeUnit.name                                        AS shortCodeUnitName\n",
    "        ,artifact.name                                        AS projectName\n",
    "        ,codeUnit.incomingDependencies                        AS incomingDependencies\n",
    "        ,codeUnit.outgoingDependencies                        AS outgoingDependencies\n",
    "        ,codeUnit.centralityArticleRank                       AS articleRank\n",
    "        ,codeUnit.centralityPageRank                          AS pageRank\n",
    "        ,codeUnit.centralityBetweenness                       AS betweenness\n",
    "\"\"\"\n",
    "\n",
    "java_type_anomaly_detection_centrality_features = query_cypher_to_data_frame(java_type_anomaly_detection_centrality_features_query)\n",
    "display(java_type_anomaly_detection_centrality_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6119f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_difference_between_article_and_page_rank(\n",
    "    java_type_anomaly_detection_centrality_features['pageRank'],\n",
    "    java_type_anomaly_detection_centrality_features['articleRank'],\n",
    "    java_type_anomaly_detection_centrality_features['shortCodeUnitName']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4965c",
   "metadata": {},
   "source": [
    "### 2.2 Local Clustering Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18501d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_type_clustering_coefficient_query = \"\"\"\n",
    "    MATCH (artifact:Java:Artifact)-[:CONTAINS]->(codeUnit:Java:Type)\n",
    "    WHERE codeUnit.incomingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.outgoingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.centralityPageRank                          IS NOT NULL\n",
    "      AND codeUnit.communityLocalClusteringCoefficient         IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANNoise                      IS NOT NULL\n",
    "   RETURN DISTINCT \n",
    "         codeUnit.fqn                                         AS codeUnitName\n",
    "        ,codeUnit.name                                        AS shortCodeUnitName\n",
    "        ,artifact.name                                        AS projectName\n",
    "        ,codeUnit.incomingDependencies                        AS incomingDependencies\n",
    "        ,codeUnit.outgoingDependencies                        AS outgoingDependencies\n",
    "        ,codeUnit.centralityPageRank                          AS pageRank\n",
    "        ,codeUnit.communityLocalClusteringCoefficient         AS clusteringCoefficient\n",
    "        ,codeUnit.clusteringHDBSCANNoise                      AS clusterNoise\n",
    "\"\"\"\n",
    "\n",
    "java_type_clustering_coefficient_features = query_cypher_to_data_frame(java_type_clustering_coefficient_query)\n",
    "display(java_type_clustering_coefficient_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering_coefficient_distribution(java_type_clustering_coefficient_features['clusteringCoefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320858c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clustering_coefficient_vs_page_rank(\n",
    "    java_type_clustering_coefficient_features['clusteringCoefficient'],\n",
    "    java_type_clustering_coefficient_features['pageRank'],\n",
    "    java_type_clustering_coefficient_features['shortCodeUnitName'],\n",
    "    java_type_clustering_coefficient_features['clusterNoise']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69256999",
   "metadata": {},
   "source": [
    "### 2.3 HDBSCAN Clusters\n",
    "\n",
    "HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) is a clustering algorithm that can identify clusters of varying densities and shapes. It is particularly useful for detecting anomalies in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765cb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_type_clustering_query = \"\"\"\n",
    "    MATCH (artifact:Java:Artifact)-[:CONTAINS]->(codeUnit:Java:Type)\n",
    "    WHERE codeUnit.incomingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.outgoingDependencies                        IS NOT NULL\n",
    "      AND codeUnit.centralityPageRank                          IS NOT NULL\n",
    "      AND codeUnit.centralityArticleRank                       IS NOT NULL\n",
    "      AND codeUnit.communityLocalClusteringCoefficient         IS NOT NULL\n",
    "      AND codeUnit.centralityBetweenness                       IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANLabel                      IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANProbability                IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANNoise                      IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANMedoid                     IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANSize                       IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANRadiusMax                  IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANRadiusAverage              IS NOT NULL\n",
    "      AND codeUnit.clusteringHDBSCANNormalizedDistanceToMedoid IS NOT NULL\n",
    "      AND codeUnit.embeddingsFastRandomProjectionTunedForClusteringVisualizationX IS NOT NULL\n",
    "      AND codeUnit.embeddingsFastRandomProjectionTunedForClusteringVisualizationY IS NOT NULL\n",
    "   RETURN DISTINCT \n",
    "         codeUnit.fqn                                         AS codeUnitName\n",
    "        ,codeUnit.name                                        AS shortCodeUnitName\n",
    "        ,artifact.name                                        AS projectName\n",
    "        ,codeUnit.incomingDependencies                        AS incomingDependencies\n",
    "        ,codeUnit.outgoingDependencies                        AS outgoingDependencies\n",
    "        ,codeUnit.centralityPageRank                          AS pageRank\n",
    "        ,1.0 - codeUnit.communityLocalClusteringCoefficient   AS inverseClusteringCoefficient\n",
    "        ,codeUnit.centralityBetweenness                       AS betweenness\n",
    "        ,codeUnit.centralityPageRank - codeUnit.centralityArticleRank AS pageToArticleRankDifference\n",
    "        ,codeUnit.clusteringHDBSCANLabel                      AS clusterLabel\n",
    "        ,codeUnit.clusteringHDBSCANProbability                AS clusterProbability\n",
    "        ,codeUnit.clusteringHDBSCANNoise                      AS clusterNoise\n",
    "        ,codeUnit.clusteringHDBSCANMedoid                     AS clusterMedoid\n",
    "        ,codeUnit.clusteringHDBSCANSize                       AS clusterSize\n",
    "        ,codeUnit.clusteringHDBSCANRadiusMax                  AS clusterRadiusMax\n",
    "        ,codeUnit.clusteringHDBSCANRadiusAverage              AS clusterRadiusAverage\n",
    "        ,codeUnit.clusteringHDBSCANNormalizedDistanceToMedoid AS clusterNormalizedDistanceToMedoid\n",
    "        ,codeUnit.embeddingsFastRandomProjectionTunedForClusteringVisualizationX AS embeddingVisualizationX\n",
    "        ,codeUnit.embeddingsFastRandomProjectionTunedForClusteringVisualizationY AS embeddingVisualizationY\n",
    "\"\"\"\n",
    "\n",
    "java_type_clustering_features = query_cypher_to_data_frame(java_type_clustering_query)\n",
    "java_type_clustering_features['degree'] = java_type_clustering_features['incomingDependencies'] + java_type_clustering_features['outgoingDependencies']\n",
    "\n",
    "display(java_type_clustering_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadf787",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_visualization_cluster_diameter(java_type_clustering_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec974d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_type_clustering_features_filtered=get_clusters_by_criteria(\n",
    "    java_type_clustering_features, by='clusterSize', ascending=False, cluster_count=20\n",
    ")\n",
    "plot_clusters(\n",
    "    clustering_visualization_dataframe=java_type_clustering_features_filtered,\n",
    "    title=\"Java Type Clusters with the largest size\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881783e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_type_clustering_features_filtered=get_clusters_by_criteria(\n",
    "    java_type_clustering_features, by='clusterRadiusMax', ascending=False, cluster_count=20\n",
    ")\n",
    "plot_clusters(\n",
    "    clustering_visualization_dataframe=java_type_clustering_features_filtered,\n",
    "    title=\"Java Type Clusters with the biggest max radius\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_type_clustering_features_filtered=get_clusters_by_criteria(\n",
    "    java_type_clustering_features, by='clusterRadiusAverage', ascending=False, cluster_count=20\n",
    ")\n",
    "plot_clusters(\n",
    "    clustering_visualization_dataframe=java_type_clustering_features_filtered,\n",
    "    title=\"Java Type Clusters with the biggest average radius\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters_probabilities(java_type_clustering_features, \"Java Type Clustering Probabilities (red=high uncertainty)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ec20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_noise(\n",
    "    clustering_visualization_dataframe=java_type_clustering_features,\n",
    "    title=\"Java Type Clustering Noise points that are surprisingly central (color) or popular (size)\",\n",
    "    size_column_name='degree',\n",
    "    color_column_name='pageRank'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d888be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_noise(\n",
    "    clustering_visualization_dataframe=java_type_clustering_features,\n",
    "    title=\"Java Type Clustering Noise points that bridge flow (color) and are poorly integrated (size)\",\n",
    "    size_column_name='inverseClusteringCoefficient',\n",
    "    color_column_name='betweenness'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9921ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_noise(\n",
    "    clustering_visualization_dataframe=java_type_clustering_features,\n",
    "    title=\"Java Type Clustering Noise points with role inversion (size), possibly violating layering or dependency direction (color)\",\n",
    "    size_column_name='pageToArticleRankDifference',\n",
    "    color_column_name='betweenness'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "JohT"
   }
  ],
  "code_graph_analysis_pipeline_data_validation": "ValidateAlwaysFalse",
  "kernelspec": {
   "display_name": "codegraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "title": "Anomaly Detection - Manual Exploration"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
