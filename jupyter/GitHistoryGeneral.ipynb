{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f0eabc4",
   "metadata": {},
   "source": [
    "# git log/history\n",
    "<br>  \n",
    "\n",
    "### References\n",
    "- [Visualizing Code: Polyglot Notebooks Repository (YouTube)](https://youtu.be/ipOpToPS-PY?si=3doePt2cp-LgEUmt)\n",
    "- [gitstractor (GitHub)](https://github.com/IntegerMan/gitstractor)\n",
    "- [Neo4j Python Driver](https://neo4j.com/docs/api/python-driver/current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57aadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from plotly import graph_objects as plotly_graph_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e64d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to distinguish between command line execution and Jupyter notebook execution\n",
    "# we need to check if the environment variable NBCONVERT is set.\n",
    "# The command line execution is required to take care of setting NBCONVERT.\n",
    "\n",
    "# Note: Even if it would be great to retain the interactivity of plotly Treemap plots (e.g. clicking into details)\n",
    "#       for command line executed notebooks (via nbconvert),\n",
    "#       it would require to execute the notebook twice: Once including interactivity and once for static Markdown and PDF.\n",
    "#       Therefore, command line executed notebooks (nbconvert) will contain static graphics (here using svg).\n",
    "def is_command_line_execution():\n",
    "    return 'NBCONVERT' in os.environ\n",
    "\n",
    "default_renderer = None\n",
    "\n",
    "if is_command_line_execution():\n",
    "    print(\"Command line execution (CLI mode): Yes\")\n",
    "    default_renderer = 'svg' # SVG is the default renderer for static (non interactive) pictures for command line execution\n",
    "else:\n",
    "    print(\"Command line execution (CLI mode): No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please set the environment variable \"NEO4J_INITIAL_PASSWORD\" in your shell \n",
    "# before starting jupyter notebook to provide the password for the user \"neo4j\". \n",
    "# It is not recommended to hardcode the password into jupyter notebook for security reasons.\n",
    "\n",
    "driver = GraphDatabase.driver(uri=\"bolt://localhost:7687\", auth=(\"neo4j\", os.environ.get(\"NEO4J_INITIAL_PASSWORD\")))\n",
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cypher_query_from_file(cypher_file_name : str):\n",
    "    with open(cypher_file_name) as file:\n",
    "        return ' '.join(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59310f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_cypher_to_data_frame(filename : str, limit: int = -1):\n",
    "    \"\"\"\n",
    "    Execute the Cypher query of the given file and returns the result.\n",
    "    filename : str : The name of the file containing the Cypher query\n",
    "    limit : int : The optional limit of rows to optimize the query. Default = -1 = no limit\n",
    "    \"\"\"\n",
    "    cypher_query = get_cypher_query_from_file(filename)\n",
    "    if limit > 0:\n",
    "        cypher_query = \"{query}\\nLIMIT {row_limit}\".format(query = cypher_query, row_limit = limit)\n",
    "    records, summary, keys = driver.execute_query(cypher_query)\n",
    "    return pd.DataFrame([r.values() for r in records], columns=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09da482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_first_non_empty_cypher_to_data_frame(*filenames : str, limit: int = -1):\n",
    "    \"\"\"\n",
    "    Executes the Cypher queries of the given files and returns the first result that is not empty.\n",
    "    If all given file names result in empty results, the last (empty) result will be returned.\n",
    "    By additionally specifying \"limit=\" the \"LIMIT\" keyword will appended to query so that only the first results get returned.\n",
    "    \"\"\"    \n",
    "    result=pd.DataFrame()\n",
    "    for filename in filenames:\n",
    "        result=query_cypher_to_data_frame(filename, limit)\n",
    "        if not result.empty:\n",
    "            return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56670c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following cell uses the build-in %html \"magic\" to override the CSS style for tables to a much smaller size.\n",
    "#This is especially needed for PDF export of tables with multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "/* CSS style for smaller dataframe tables. */\n",
    ".dataframe th {\n",
    "    font-size: 8px;\n",
    "}\n",
    ".dataframe td {\n",
    "    font-size: 8px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame Display Configuration\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17f2aa",
   "metadata": {},
   "source": [
    "## Git History - Directory Commit Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first part provides functions that provide basic functionality for the following parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da524e",
   "metadata": {},
   "source": [
    "### Treemap Layout Functions and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841967e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base settings for Plotly Treemap\n",
    "\n",
    "plotly_treemap_layout_base_settings = dict(\n",
    "    margin=dict(t=50, l=15, r=15, b=15),\n",
    ")\n",
    "plotly_treemap_figure_show_settings = dict(\n",
    "    renderer=\"svg\" if is_command_line_execution() else None,\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "plotly_treemap_marker_base_style = dict(\n",
    "    cornerradius=5, \n",
    ")\n",
    "\n",
    "plotly_treemap_marker_base_colorscale = dict(\n",
    "    **plotly_treemap_marker_base_style,\n",
    "    colorscale='Hot_r', #  Hot_r, ice_r, Viridis_r, speed_r, haline_r, thermal_r, Plasma_r, solar_r, Electric_r, Blackbody_r, deep_r, Turbo_r, amp, Reds, Blackbody_r, RdGy_r, RdBu_r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_treemap_commit_statistics_settings(data_frame: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Creates a Plotly Treemap with the given settings and data frame.\n",
    "    data_frame : pd.DataFrame : The input data frame\n",
    "    return :plotly_graph_objects.Treemap : The prepared Plotly Treemap\n",
    "    \"\"\"\n",
    "    return plotly_graph_objects.Treemap(\n",
    "        labels=data_frame['directoryName'],\n",
    "        parents=data_frame['directoryParentPath'],\n",
    "        ids=data_frame['directoryPath'],\n",
    "        customdata=data_frame[['fileCount', 'commitCount', 'authorCount', 'lastCommitDate', 'daysSinceLastCommit', 'lastCreationDate', 'daysSinceLastCreation', 'lastModificationDate', 'daysSinceLastModification', 'directoryPath']],\n",
    "        hovertemplate='<b>%{label}</b><br>Files: %{customdata[0]}<br>Commits: %{customdata[1]}<br>Authors: %{customdata[2]}<br>Last Commit: %{customdata[3]} (%{customdata[4]} days ago)<br>Last Created: %{customdata[5]} (%{customdata[6]} days ago)<br>Last Modified: %{customdata[7]} (%{customdata[8]} days ago)<br>Path: %{customdata[9]}',\n",
    "        maxdepth=-1,\n",
    "        root_color=\"lightgrey\",\n",
    "        marker=dict(**plotly_treemap_marker_base_style),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacc415",
   "metadata": {},
   "source": [
    "### Visualization Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83077395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quantile_limited_column(input_data_frame : pd.DataFrame, column_name : str, quantile : float = 0.95) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Limits the values of the given column in the input data frame to the given quantile.\n",
    "    The values are not filtered out but set to the limited (integer quantile value).\n",
    "    input_data_frame : pd.DataFrame : The input data frame\n",
    "    column_name : str : The name of the column to limit\n",
    "    quantile : float : The quantile to limit the values to (default: 0.95)\n",
    "    return : pd.DataFrame : The modified dataframe with the added column (column_name + '_limited')\n",
    "    \"\"\"\n",
    "    data_frame=input_data_frame.copy()\n",
    "    column_values = data_frame[column_name]\n",
    "    column_limit = column_values.quantile(quantile)\n",
    "    data_frame[column_name + '_limited'] = np.where(column_values > column_limit, column_limit, column_values)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rank_column(input_data_frame : pd.DataFrame, column_name : str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a rank column (\"dense\" mode) to the input data frame based on the given column name.\n",
    "    input_data_frame : pd.DataFrame : The input data frame\n",
    "    column_name : str : The name of the column to rank\n",
    "    return : pd.DataFrame : The modified dataframe with the added rank column\n",
    "    \"\"\"\n",
    "    data_frame=input_data_frame.copy()\n",
    "    data_frame[column_name + '_rank'] = data_frame[column_name].rank(ascending=True, method='dense')\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da109679",
   "metadata": {},
   "source": [
    "### File Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_file_path_element(file_path_elements: list) -> list:\n",
    "    \"\"\"\n",
    "    Removes the last element of the file path so that only the directory names retain.\n",
    "    file_path_elements : list : The list of levels to remove\n",
    "    return : list : The list of the directories\n",
    "    \"\"\"\n",
    "    return file_path_elements[:-1] if len(file_path_elements) > 1 else ['']\n",
    "\n",
    "def convert_path_elements_to_directories(file_path_elements: list) -> list:\n",
    "    \"\"\"\n",
    "    Converts the file path elements into directories.\n",
    "    file_path_elements : list : The list of levels to convert\n",
    "    return : list : The list of directories\n",
    "    \"\"\"\n",
    "    directories = remove_last_file_path_element(file_path_elements)\n",
    "    return ['/'.join(directories[:i+1]) for i in range(len(directories))]\n",
    "\n",
    "def add_directory_column(input_dataframe: pd.DataFrame, file_path_column: str, directory_column: str = 'directoryPath'):\n",
    "    \"\"\"\n",
    "    Adds a directory column to the input DataFrame based on the file path column.\n",
    "    input_dataframe : pd.DataFrame : The input DataFrame\n",
    "    file_path_column : str : The name of the file path column\n",
    "    directory_column : str : The name of the directory column to be added\n",
    "    return : pd.DataFrame : The DataFrame with added directory column\n",
    "    \"\"\"\n",
    "    if directory_column in input_dataframe.columns:\n",
    "        return input_dataframe # Column already exists\n",
    "    \n",
    "    input_dataframe.insert(0, directory_column, input_dataframe[file_path_column].str.split('/').apply(convert_path_elements_to_directories))\n",
    "    input_dataframe = input_dataframe.explode(directory_column)\n",
    "    return input_dataframe\n",
    "\n",
    "def add_directory_name_column(input_dataframe: pd.DataFrame, directory_column: str = 'directoryPath', directory_name_column: str = 'directoryName'):\n",
    "    \"\"\"\n",
    "    Adds a directory name column to the input DataFrame based on the directory column.\n",
    "    input_dataframe : pd.DataFrame : The input DataFrame\n",
    "    directory_column : str : The name of the directory column\n",
    "    directory_name_column : str : The name of the directory name column to be added\n",
    "    return : pd.DataFrame : The DataFrame with added directory name column\n",
    "    \"\"\"\n",
    "    if directory_name_column in input_dataframe.columns:\n",
    "        return input_dataframe # Column already exists\n",
    "    \n",
    "    splitted_directories = input_dataframe[directory_column].str.rsplit('/', n=1)\n",
    "    input_dataframe.insert(1, directory_name_column, splitted_directories.apply(lambda x: (x[-1])))\n",
    "    return input_dataframe\n",
    "\n",
    "def add_parent_directory_column(input_dataframe: pd.DataFrame, directory_column: str = 'directoryPath', directory_parent_column: str = 'directoryParentPath'):\n",
    "    \"\"\"\n",
    "    Adds a directory parent column to the input DataFrame based on the directory column.\n",
    "    input_dataframe : pd.DataFrame : The input DataFrame\n",
    "    directory_column : str : The name of the directory column\n",
    "    directory_parent_column : str : The name of the directory parent column to be added\n",
    "    return : pd.DataFrame : The DataFrame with added directory parent column\n",
    "    \"\"\"\n",
    "    if directory_parent_column in input_dataframe.columns:\n",
    "        return input_dataframe # Column already exists\n",
    "    \n",
    "    # Remove last path element from directory_column to get the directory_parent_column\n",
    "    splitted_directories = input_dataframe[directory_column].str.rsplit('/', n=1)\n",
    "    input_dataframe.insert(1, directory_parent_column, splitted_directories.apply(lambda x: (x[0])))\n",
    "    \n",
    "    # Clear parent (set to empty string) when it equal to the directory\n",
    "    input_dataframe.loc[input_dataframe[directory_parent_column] == input_dataframe[directory_column], directory_parent_column] = ''\n",
    "    return input_dataframe\n",
    "\n",
    "def second_entry(values: pd.Series):\n",
    "    \"\"\"\n",
    "    Returns the second entry of a list of values.\n",
    "    Meant to be used as an aggregation function for dataframe grouping.\n",
    "    values : Series : The pandas Series of values\n",
    "    return : any : The second entry\n",
    "    \"\"\"\n",
    "    return values.iloc[1] if len(values) > 1 else None\n",
    "\n",
    "def get_file_count_from_aggregated_file_paths(values: pd.Series):\n",
    "    \"\"\"\n",
    "    Return the file count from an array of array of file paths.\n",
    "    Meant to be used as an aggregation function for dataframe grouping.\n",
    "    values : Series : The pandas Series of values\n",
    "    return : int : The number of files\n",
    "    \"\"\"\n",
    "    return len(np.unique(np.concatenate(values.to_list())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aeae9b",
   "metadata": {},
   "source": [
    "### File Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d8aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_files_with_commit_statistics = query_cypher_to_data_frame(\"../cypher/GitLog/List_git_files_with_commit_statistics_by_author.cypher\")\n",
    "\n",
    "# Debug\n",
    "# display(\"1. query result ---------------------\")\n",
    "# display(git_files_with_commit_statistics)\n",
    "\n",
    "# Add multiple rows for each file path containing all its directories paths in the new column 'directoryPath'\n",
    "git_files_with_commit_statistics = add_directory_column(git_files_with_commit_statistics, 'filePath', 'directoryPath')\n",
    "\n",
    "# Debug\n",
    "# display(\"2. added directoryPath --------------\")\n",
    "# display(git_files_with_commit_statistics)\n",
    "\n",
    "# Define how common non-grouped columns will be aggregated.\n",
    "# Hint: maxCommitSha might not seem very useful, but it actually helps by group similar directories in the final step\n",
    "common_named_aggregation = dict(\n",
    "    commitCount=pd.NamedAgg(column=\"commitCount\", aggfunc=\"sum\"),\n",
    "    daysSinceLastCommit=pd.NamedAgg(column=\"daysSinceLastCommit\", aggfunc=\"min\"),\n",
    "    daysSinceLastCreation=pd.NamedAgg(column=\"daysSinceLastCreation\", aggfunc=\"min\"),\n",
    "    daysSinceLastModification=pd.NamedAgg(column=\"daysSinceLastModification\", aggfunc=\"min\"),\n",
    "    lastCommitDate=pd.NamedAgg(column=\"lastCommitDate\", aggfunc=\"max\"),\n",
    "    lastCreationDate=pd.NamedAgg(column=\"lastCreationDate\", aggfunc=\"max\"),\n",
    "    lastModificationDate=pd.NamedAgg(column=\"lastModificationDate\", aggfunc=\"max\"),\n",
    "    maxCommitSha=pd.NamedAgg(column=\"maxCommitSha\", aggfunc=\"max\"),\n",
    ")\n",
    "\n",
    "# Group the git files by their directory and author and count the number of files of each directory (across all levels).\n",
    "git_files_with_commit_statistics = git_files_with_commit_statistics.groupby(['directoryPath', 'author']).aggregate(\n",
    "    filePaths=pd.NamedAgg(column=\"filePath\", aggfunc=np.unique),\n",
    "    firstFile=pd.NamedAgg(column=\"filePath\", aggfunc=\"first\"),\n",
    "    **common_named_aggregation\n",
    ")\n",
    "\n",
    "# Sort the grouped and aggregated entries by the name of the directory ascending and the number of commits descending.\n",
    "# The author with the most commits will then be listed first for each directory.\n",
    "git_files_with_commit_statistics = git_files_with_commit_statistics.sort_values(by=['directoryPath', 'commitCount'], ascending=[True, False])\n",
    "git_files_with_commit_statistics = git_files_with_commit_statistics.reset_index()\n",
    "\n",
    "# Debug\n",
    "# display(\"3. grouped by 'directoryPath' and 'author' -----\")\n",
    "# display(git_files_with_commit_statistics)\n",
    "\n",
    "# Group the entries again now only by their directory path to get the aggregated number of authors, the main author and the second author.\n",
    "# Hint: firstFile (similar to maxCommitSha) might not seem very useful, but it also helps to group similar directories in the final step\n",
    "git_files_with_commit_statistics = git_files_with_commit_statistics.groupby('directoryPath').aggregate(\n",
    "    fileCount=pd.NamedAgg(column=\"filePaths\", aggfunc=get_file_count_from_aggregated_file_paths),\n",
    "    firstFile=pd.NamedAgg(column=\"firstFile\", aggfunc=\"first\"),\n",
    "    authorCount=pd.NamedAgg(column=\"author\", aggfunc=\"nunique\"),\n",
    "    mainAuthor=pd.NamedAgg(column=\"author\", aggfunc=\"first\"),\n",
    "    secondAuthor=pd.NamedAgg(column=\"author\", aggfunc=second_entry),\n",
    "    **common_named_aggregation\n",
    ")\n",
    "git_files_with_commit_statistics = git_files_with_commit_statistics.reset_index()\n",
    "\n",
    "# Debug\n",
    "# display(\"4. grouped by 'directoryPath' ----------------------\")\n",
    "# display(git_files_with_commit_statistics)\n",
    "\n",
    "# Add the name of the directory (last '/' separated element) and the parent directory path to the table.\n",
    "git_files_with_commit_statistics = add_directory_name_column(git_files_with_commit_statistics, 'directoryPath', 'directoryName')\n",
    "git_files_with_commit_statistics = add_parent_directory_column(git_files_with_commit_statistics, 'directoryPath', 'directoryParentPath')\n",
    "\n",
    "# Debug\n",
    "# display(\"5. added parent and name columns ------------\")\n",
    "# display(git_files_with_commit_statistics)\n",
    "\n",
    "# Group finally by all columns except for the directory name, parent and path (first 3 columns) and pick the longest (max) directory path in case there are multiple.\n",
    "all_column_names_except_for_the_directory_path = git_files_with_commit_statistics.columns.to_list()[3:]\n",
    "git_files_with_commit_statistics = git_files_with_commit_statistics.groupby(all_column_names_except_for_the_directory_path).aggregate(\n",
    "   directoryName=pd.NamedAgg(column=\"directoryName\", aggfunc=lambda names: '/'.join(names)),\n",
    "   directoryParentPath=pd.NamedAgg(column=\"directoryParentPath\", aggfunc=\"first\"),\n",
    "   directoryPath=pd.NamedAgg(column=\"directoryPath\", aggfunc=\"last\"),\n",
    ")\n",
    "# Reorder the column positions so that the directory path is again the first column. \n",
    "all_column_names_with_the_directory_path_first = ['directoryPath', 'directoryParentPath', 'directoryName'] + all_column_names_except_for_the_directory_path\n",
    "git_files_with_commit_statistics = git_files_with_commit_statistics.reset_index()[all_column_names_with_the_directory_path_first]\n",
    "\n",
    "# Debug\n",
    "# display(\"6. grouped by all except for directory path, name and parent columns (max) ----------------------\")\n",
    "# display(git_files_with_commit_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f8d4b",
   "metadata": {},
   "source": [
    "### Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_files_with_commit_statistics.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc11f52",
   "metadata": {},
   "source": [
    "### Directories by file count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0dc138",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plotly_graph_objects.Figure(plotly_graph_objects.Treemap(\n",
    "    create_treemap_commit_statistics_settings(git_files_with_commit_statistics),\n",
    "    values = git_files_with_commit_statistics['fileCount'],\n",
    "))\n",
    "figure.update_layout(\n",
    "    **plotly_treemap_layout_base_settings,\n",
    "    title='Directories and their file count'\n",
    ")\n",
    "figure.show(**plotly_treemap_figure_show_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb399f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Directories by main author"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ca7b1",
   "metadata": {},
   "source": [
    "### Number of commits per directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_commit_count_per_directory = add_quantile_limited_column(git_files_with_commit_statistics, \"commitCount\", 0.98)\n",
    "\n",
    "figure = plotly_graph_objects.Figure(plotly_graph_objects.Treemap(\n",
    "    create_treemap_commit_statistics_settings(git_commit_count_per_directory),\n",
    "    values = git_commit_count_per_directory['fileCount'],\n",
    "    marker=dict(\n",
    "        **plotly_treemap_marker_base_colorscale,\n",
    "        colors=git_commit_count_per_directory['commitCount_limited'], \n",
    "        colorbar=dict(title=\"Commits\"),\n",
    "    ),\n",
    "))\n",
    "figure.update_layout(\n",
    "    **plotly_treemap_layout_base_settings,\n",
    "    title='Number of git commits',\n",
    ")\n",
    "figure.show(**plotly_treemap_figure_show_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def69b07",
   "metadata": {},
   "source": [
    "### Number of distinct authors per directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_commit_authors_per_directory = add_quantile_limited_column(git_files_with_commit_statistics, \"authorCount\", 0.96)\n",
    "\n",
    "figure = plotly_graph_objects.Figure(plotly_graph_objects.Treemap(\n",
    "    create_treemap_commit_statistics_settings(git_commit_authors_per_directory),\n",
    "    values = git_commit_authors_per_directory['fileCount'],\n",
    "    marker=dict(\n",
    "        **plotly_treemap_marker_base_colorscale,\n",
    "        colors=git_commit_authors_per_directory['authorCount_limited'], \n",
    "        colorbar=dict(title=\"Authors\"),\n",
    "    ),\n",
    "))\n",
    "figure.update_layout(\n",
    "    **plotly_treemap_layout_base_settings,\n",
    "    title='Number of distinct commit authors',\n",
    ")\n",
    "figure.show(**plotly_treemap_figure_show_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed919b0",
   "metadata": {},
   "source": [
    "### Days since last commit per directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6929154",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_commit_days_since_last_commit_per_directory = add_rank_column(git_files_with_commit_statistics, \"daysSinceLastCommit\")\n",
    "\n",
    "figure = plotly_graph_objects.Figure(plotly_graph_objects.Treemap(\n",
    "    create_treemap_commit_statistics_settings(git_commit_days_since_last_commit_per_directory),\n",
    "    values = git_commit_days_since_last_commit_per_directory['fileCount'],\n",
    "    marker=dict(\n",
    "        **plotly_treemap_marker_base_colorscale,\n",
    "        colors=git_commit_days_since_last_commit_per_directory['daysSinceLastCommit_limited'], \n",
    "        colorbar=dict(title=\"Days\"),\n",
    "    ),\n",
    "))\n",
    "\n",
    "figure.update_layout(\n",
    "    **plotly_treemap_layout_base_settings,\n",
    "    title='Days since last commit',\n",
    ")\n",
    "figure.show(**plotly_treemap_figure_show_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f6d20",
   "metadata": {},
   "source": [
    "### Days since last commit per directory (ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720aa99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plotly_graph_objects.Figure(plotly_graph_objects.Treemap(\n",
    "    create_treemap_commit_statistics_settings(git_commit_days_since_last_commit_per_directory),\n",
    "    values = git_commit_days_since_last_commit_per_directory['fileCount'],\n",
    "    marker=dict(\n",
    "        **plotly_treemap_marker_base_colorscale,\n",
    "        colors=git_commit_days_since_last_commit_per_directory['daysSinceLastCommit_rank'], \n",
    "        colorbar=dict(title=\"Rank\"),\n",
    "    ),\n",
    "))\n",
    "\n",
    "figure.update_layout(\n",
    "    **plotly_treemap_layout_base_settings,\n",
    "    title='Rank of days since last commit',\n",
    ")\n",
    "figure.show(**plotly_treemap_figure_show_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf96f7",
   "metadata": {},
   "source": [
    "### Days since last file creation per directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de46c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_commit_days_since_last_file_creation_per_directory = add_rank_column(git_files_with_commit_statistics, \"daysSinceLastCreation\")\n",
    "\n",
    "figure = plotly_graph_objects.Figure(plotly_graph_objects.Treemap(\n",
    "    create_treemap_commit_statistics_settings(git_commit_days_since_last_file_creation_per_directory),\n",
    "    values = git_commit_days_since_last_file_creation_per_directory['fileCount'],\n",
    "    marker=dict(\n",
    "        **plotly_treemap_marker_base_colorscale,\n",
    "        colors=git_commit_days_since_last_file_creation_per_directory['daysSinceLastCreation_limited'], \n",
    "        colorbar=dict(title=\"Days\"),\n",
    "    ),\n",
    "))\n",
    "figure.update_layout(\n",
    "    **plotly_treemap_layout_base_settings,\n",
    "    title='Days since last file creation',\n",
    ")\n",
    "figure.show(**plotly_treemap_figure_show_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772eab2a",
   "metadata": {},
   "source": [
    "### Days since last file creation per directory (ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d918ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plotly_graph_objects.Figure(plotly_graph_objects.Treemap(\n",
    "    create_treemap_commit_statistics_settings(git_commit_days_since_last_file_creation_per_directory),\n",
    "    values = git_commit_days_since_last_file_creation_per_directory['fileCount'],\n",
    "    marker=dict(\n",
    "        **plotly_treemap_marker_base_colorscale,\n",
    "        colors=git_commit_days_since_last_file_creation_per_directory['daysSinceLastCreation_rank'], \n",
    "        colorbar=dict(title=\"Rank\"),\n",
    "    ),\n",
    "))\n",
    "figure.update_layout(\n",
    "    **plotly_treemap_layout_base_settings,\n",
    "    title='Rank of days since last file creation',\n",
    ")\n",
    "figure.show(**plotly_treemap_figure_show_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c46d5",
   "metadata": {},
   "source": [
    "### Days since last file modification per directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423fdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_commit_days_since_last_file_modification_per_directory = add_rank_column(git_files_with_commit_statistics, \"daysSinceLastModification\")\n",
    "\n",
    "figure = plotly_graph_objects.Figure(plotly_graph_objects.Treemap(\n",
    "    create_treemap_commit_statistics_settings(git_commit_days_since_last_file_modification_per_directory),\n",
    "    values = git_commit_days_since_last_file_modification_per_directory['fileCount'],\n",
    "    marker=dict(\n",
    "        **plotly_treemap_marker_base_colorscale,\n",
    "        colors=git_commit_days_since_last_file_modification_per_directory['daysSinceLastModification_limited'], \n",
    "        colorbar=dict(title=\"Days\"),\n",
    "    ),\n",
    "))\n",
    "figure.update_layout(\n",
    "    **plotly_treemap_layout_base_settings,\n",
    "    title='Days since last file modification',\n",
    ")\n",
    "figure.show(**plotly_treemap_figure_show_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abc96e4",
   "metadata": {},
   "source": [
    "### Days since last file modification per directory (ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c33849",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plotly_graph_objects.Figure(plotly_graph_objects.Treemap(\n",
    "    create_treemap_commit_statistics_settings(git_commit_days_since_last_file_modification_per_directory),\n",
    "    values = git_commit_days_since_last_file_modification_per_directory['fileCount'],\n",
    "    marker=dict(\n",
    "        **plotly_treemap_marker_base_colorscale,\n",
    "        colors=git_commit_days_since_last_file_modification_per_directory['daysSinceLastModification_rank'], \n",
    "        colorbar=dict(title=\"Rank\"),\n",
    "    ),\n",
    "))\n",
    "figure.update_layout(\n",
    "    **plotly_treemap_layout_base_settings,\n",
    "    title='Rank of days since last file modification',\n",
    ")\n",
    "figure.show(**plotly_treemap_figure_show_settings)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "JohT"
   }
  ],
  "code_graph_analysis_pipeline_data_validation": "ValidateGitHistory",
  "kernelspec": {
   "display_name": "codegraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "title": "Git History Charts with Neo4j"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
